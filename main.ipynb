{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wbdata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "import re\n",
    "from ast import literal_eval  #Is used to safely evaluate a string that looks like a Python literal \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The World Bank database for data source 2 contains several groups of indicators. We aim to use at least one indicator from each group\n",
    "\n",
    "### **Group 1: AG - Agriculture & Land Use**\n",
    "1. **AG.LND.AGRI.ZS** (Agricultural land % of total area)  \n",
    "   - *Why?* Shows economic dependence on agriculture.  \n",
    "2. **AG.PRD.CREL.MT** (Cereal production in metric tons)  \n",
    "   - *Why?* Measures agricultural output efficiency.  \n",
    "\n",
    "### **Group 2: BM/BX - Trade & Balance of Payments**  \n",
    "1. **BX.GSR.GNFS.CD** (Exports of goods/services, current USD)  \n",
    "   - *Why?* Directly contributes to GDP.  \n",
    "2. **BM.KLT.DINV.WD.GD.ZS** (FDI net inflows % of GDP)  \n",
    "   - *Why?* Foreign investment drives economic growth.  \n",
    "\n",
    "### **Group 3: DT/DC - Debt & Development Aid**  \n",
    "1. **DT.DOD.DECT.GN.ZS** (External debt % of GNI)  \n",
    "   - *Why?* High debt can constrain GDP growth.  \n",
    "2. **DC.ODA.TOTL.GD.ZS** (Net ODA % of GDP)  \n",
    "   - *Why?* Aid can stimulate economic activity.  \n",
    "\n",
    "### **Group 4: EN/EG - Environment & Energy**  \n",
    "1. **EG.USE.ELEC.KH.PC** (Electric power consumption per capita)  \n",
    "   - *Why?* Proxy for industrialization/development.  \n",
    "2. **EN.ATM.CO2.PC** (CO2 emissions per capita)  \n",
    "   - *Why?* Ties economic activity to environmental impact.  \n",
    "\n",
    "### **Group 5: SE/SP - Education & Population**  \n",
    "1. **SE.SEC.ENRR** (Secondary school enrollment rate)  \n",
    "   - *Why?* Skilled workforce boosts productivity.  \n",
    "2. **SP.POP.1564.TO.ZS** (Working-age population %)  \n",
    "   - *Why?* Demographic dividend affects GDP.  \n",
    "\n",
    "### **Group 6: SH/SN - Health & Nutrition**  \n",
    "1. **SH.DYN.MORT** (Under-5 mortality rate)  \n",
    "   - *Why?* Health outcomes correlate with economic stability.  \n",
    "2. **SN.ITK.DEFC.ZS** (Prevalence of undernourishment)  \n",
    "   - *Why?* Malnutrition reduces labor productivity.  \n",
    "\n",
    "### **Group 7: SL/SI - Labor & Poverty**  \n",
    "1. **SL.UEM.TOTL.ZS** (Unemployment rate)  \n",
    "   - *Why?* Directly impacts economic output.  \n",
    "2. **SI.POV.GINI** (Gini inequality index)  \n",
    "   - *Why?* Inequality can hinder growth.  \n",
    "\n",
    "### **Group 8: IT/IC - Technology & Infrastructure**  \n",
    "1. **IT.NET.USER.ZS** (Internet users % of population)  \n",
    "   - *Why?* Digitalization drives modern economies.  \n",
    "2. **IC.BUS.NREG** (New businesses registered)  \n",
    "   - *Why?* Entrepreneurship fuels GDP growth.  \n",
    "\n",
    "### **Group 9: GC/GF - Government Finance**  \n",
    "1. **GC.TAX.TOTL.GD.ZS** (Tax revenue % of GDP)  \n",
    "   - *Why?* Reflects government capacity to invest.  \n",
    "2. **GF.XPD.BUDG.ZS** (Govt expenditure % of budget)  \n",
    "   - *Why?* Public spending stimulates GDP.  \n",
    "\n",
    "### **Group 10: VA/PV/RL - Governance & Institutions**  \n",
    "1. **RL.EST** (Rule of Law index)  \n",
    "   - *Why?* Strong institutions attract investment.  \n",
    "2. **VA.EST** (Voice/Accountability index)  \n",
    "   - *Why?* Political stability enables growth.  \n",
    "\n",
    "### **Group 11: TX/TM - Trade Logistics**  \n",
    "1. **TX.VAL.MRCH.CD.WT** (Merchandise exports, current USD)  \n",
    "   - *Why?* Export performance drives GDP.  \n",
    "2. **TM.TAX.MRCH.WM.AR.ZS** (Weighted mean tariff rate)  \n",
    "   - *Why?* Trade barriers affect economic activity.  \n",
    "\n",
    "### **Group 12: ER/SM - Water & Migration**  \n",
    "1. **ER.H2O.FWTL.ZS** (Freshwater withdrawals % of resources)  \n",
    "   - *Why?* Water stress impacts agriculture/industry.  \n",
    "2. **SM.POP.TOTL.ZS** (International migrant stock %)  \n",
    "   - *Why?* Migration can supplement labor force.  \n",
    "\n",
    "### **Group 13: NY/NE - Macroeconomic Indicators**  \n",
    "1. **NY.GDP.MKTP.CD** (GDP, current USD)  \n",
    "   - *Why?* Target variable for prediction.  \n",
    "2. **NE.EXP.GNFS.ZS** (Exports % of GDP)  \n",
    "   - *Why?* Key GDP component.  \n",
    "\n",
    "### **Group 14: FD/FI - Financial Sector**  \n",
    "1. **FD.AST.PRVT.GD.ZS** (Domestic credit to private sector % of GDP)  \n",
    "   - *Why?* Credit access enables business growth.  \n",
    "2. **FI.RES.TOTL.CD** (Total reserves, current USD)  \n",
    "   - *Why?* Reserves stabilize the economy.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Use OpenAI tokenizer to calculate token lengths (optional, more accurate)\n",
    "def estimate_token_count(text, model=\"gpt-3.5-turbo-instruct\"):\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    return len(enc.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_prompt  = \"\"\"\n",
    "You are a data scientist tasked with selecting the most relevant development indicators to predict when a country will reach the GDP per capita level of developed countries.\n",
    "\n",
    "Below is a list of available indicators retrieved from the World Bank data source 2. Each item consists of an indicator code and its corresponding name:\n",
    "\n",
    "{chunked_indicators}\n",
    "\n",
    "Your task:\n",
    "- Select indicators that are **strongly related to GDP growth**, **economic development**, or **structural transition** (e.g. education, infrastructure, industrialization, trade, institutions).\n",
    "- Prefer indicators that are **leading indicators** or have **causal influence** on development, not just GDP itself.\n",
    "- Include **diverse dimensions**: macroeconomic, infrastructure, education, health, technology, labor, governance, etc.\n",
    "- Limit to {number_of_indicators_per_chunk} indicators.\n",
    "- Output only a Python dictionary like this without any comments:\n",
    "\n",
    "dict_indicators = {{\n",
    "    'CODE1': 'Indicator Name 1',\n",
    "    'CODE2': 'Indicator Name 2',\n",
    "    ...\n",
    "}} \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "available_indicators = wbdata.get_indicators(source=2)\n",
    "# available_str = \"\\n\".join([f\"{i['id']}: {i['name']}\" for i in available_indicators])\n",
    "df_indicators = pd.DataFrame(available_indicators)[['id','name']]\n",
    "\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo-instruct\")\n",
    "df_indicators[\"token_count\"] = df_indicators[\"name\"].apply(lambda x: len(enc.encode(x)))\n",
    "\n",
    "base_prompt_count = estimate_token_count(base_prompt)\n",
    "\n",
    "\n",
    "\n",
    "model_max_tokens = 2500   # Model's maximum context length is 4097 tokens\n",
    "\n",
    "max_prompt_tokens = model_max_tokens - base_prompt_count\n",
    "\n",
    "chunk_index = []\n",
    "\n",
    "for i in range(1,len(df_indicators)):\n",
    "    if len(chunk_index) == 0:\n",
    "        list_indicators = \"\\n\".join((df_indicators[\"id\"][0:i] + \": \" + df_indicators[\"name\"][0:i]).tolist())\n",
    "        token_count = estimate_token_count(list_indicators)\n",
    "    else:\n",
    "        list_indicators = \"\\n\".join((df_indicators[\"id\"][current_index:i] + \": \" + df_indicators[\"name\"][current_index:i]).tolist())\n",
    "        token_count = estimate_token_count(list_indicators)\n",
    "    if token_count>max_prompt_tokens:\n",
    "        current_index = i\n",
    "        chunk_index.append(i)\n",
    "        token_count = 0\n",
    "\n",
    "list_indicators = (df_indicators[\"id\"] + \": \" + df_indicators[\"name\"]).tolist()\n",
    "\n",
    "chunks = [\n",
    "    list_indicators[0:index] if i == 0 \n",
    "    else list_indicators[chunk_index[i-1]:index]\n",
    "    for i, index in enumerate(chunk_index)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "with open(\"credentials.json\", \"r\") as file:\n",
    "    credentials = json.load(file)\n",
    "\n",
    "# Initialize the client\n",
    "client = OpenAI(\n",
    "    api_key=credentials[\"OPENAI_API_KEY\"],\n",
    "    base_url=credentials[\"OPENAI_API_BASE\"]  # Only if using a proxy/alternative endpoint\n",
    ")\n",
    "\n",
    "# Decoding parameters\n",
    "TEMPERATURE = 0.0\n",
    "def query_openai(prompt):\n",
    "\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=300  \n",
    "\n",
    "    )\n",
    "    time.sleep(5)  # rate limiting\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Running chunk 1/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 2/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 3/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 4/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 5/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 6/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 7/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 8/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 9/14...\n",
      "Attempt 1... Error: unterminated string literal (detected at line 1) (<unknown>, line 1)\n",
      "Attempt 2... Error: unterminated string literal (detected at line 1) (<unknown>, line 1)\n",
      "Attempt 3... Error: unterminated string literal (detected at line 1) (<unknown>, line 1)\n",
      "Failed chunk 9 after 3 attempts.\n",
      "\n",
      " Running chunk 10/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 11/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 12/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 13/14...\n",
      "Attempt 1... Success.\n",
      "\n",
      " Running chunk 14/14...\n",
      "Attempt 1... Success.\n"
     ]
    }
   ],
   "source": [
    "max_indicators = 30\n",
    "n_chunks =  len(chunks)\n",
    "number_of_indicators_per_chunk = math.ceil(max_indicators/n_chunks)\n",
    "\n",
    "merged_dict = {}\n",
    "\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"\\n Running chunk {idx+1}/{n_chunks}...\")\n",
    "    chunk_text = \"\\n\".join(chunk)\n",
    "\n",
    "    prompt = base_prompt.format(\n",
    "        chunked_indicators=chunk_text,\n",
    "        number_of_indicators_per_chunk=number_of_indicators_per_chunk\n",
    "    )\n",
    "    \n",
    "    success = False\n",
    "    retries = 3\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            print(f\"Attempt {attempt}...\", end=\" \")\n",
    "            response = query_openai(prompt)\n",
    "            \n",
    "            # extract dict with regex\n",
    "            raw_text = response.choices[0].text.replace('\\r', '').replace('\\n', '').replace('\\t', '').strip()\n",
    "\n",
    "            match = re.search(r\"\\{.*?\\}\", raw_text, re.DOTALL)\n",
    "            if not match:\n",
    "                raise ValueError(\"No dictionary found in model response.\")\n",
    "            \n",
    "            chunk_dict = literal_eval(match.group(0))\n",
    "            merged_dict.update(chunk_dict)\n",
    "            print(\"Success.\")\n",
    "            success = True\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            if attempt < retries:\n",
    "                time.sleep(5)  # wait before retry\n",
    "            else:\n",
    "                print(f\"Failed chunk {idx+1} after {retries} attempts.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m response \u001b[38;5;241m=\u001b[39m query_openai(chunks[\u001b[38;5;241m8\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# extract dict with regex\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m raw_text \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      6\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m.*?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m, raw_text, re\u001b[38;5;241m.\u001b[39mDOTALL)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "response = query_openai(chunks[8])\n",
    "\n",
    "# extract dict with regex\n",
    "raw_text = response.choices[0].text.replace('\\r', '').replace('\\n', '').replace('\\t', '').strip()\n",
    "\n",
    "match = re.search(r\"\\{.*?\\}\", raw_text, re.DOTALL)\n",
    "if not match:\n",
    "    raise ValueError(\"No dictionary found in model response.\")\n",
    "\n",
    "chunk_dict = literal_eval(match.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id=None, choices=None, created=None, model=None, object=None, system_fingerprint=None, usage=None, error={'message': 'Too many parallel completions requested. You submitted 104 prompts, but you can currently request up to at most a total of 20). Please contact us through our help center at help.openai.com for further questions.', 'type': 'invalid_request_error', 'param': None, 'code': None})"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    'SE.PRM.ENRR': 'School enrollment, primary (% gross)',\n",
      "    'SE.SEC.ENRR': 'School enrollment, secondary (% gross)',\n",
      "    'SE.TER.CUAT.BA.ZS': 'Educational attainment, at least Bachelor's or equivalent, population 25+, total (%) (cumulative)'\n",
      "}\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'{' was never closed (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mh:\\Python\\Udacity\\World_Bank_Data\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3579\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[133], line 2\u001b[0m\n    literal_eval(match.group(0))\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ast.py:62\u001b[0m in \u001b[0;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ast.py:50\u001b[1;36m in \u001b[1;35mparse\u001b[1;36m\n\u001b[1;33m    return compile(source, filename, mode, flags,\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<unknown>:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    {\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '{' was never closed\n"
     ]
    }
   ],
   "source": [
    "print(match.group(0))\n",
    "literal_eval(match.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a data scientist tasked with selecting the most relevant development indicators to predict when a country will reach the GDP per capita level of developed countries.\n",
      "\n",
      "Below is a list of available indicators retrieved from the World Bank data source 2. Each item consists of an indicator code and its corresponding name:\n",
      "\n",
      "AG.CON.FERT.PT.ZS: Fertilizer consumption (% of fertilizer production)\n",
      "AG.CON.FERT.ZS: Fertilizer consumption (kilograms per hectare of arable land)\n",
      "AG.LND.AGRI.K2: Agricultural land (sq. km)\n",
      "AG.LND.AGRI.ZS: Agricultural land (% of land area)\n",
      "AG.LND.ARBL.HA: Arable land (hectares)\n",
      "AG.LND.ARBL.HA.PC: Arable land (hectares per person)\n",
      "AG.LND.ARBL.ZS: Arable land (% of land area)\n",
      "AG.LND.CREL.HA: Land under cereal production (hectares)\n",
      "AG.LND.CROP.ZS: Permanent cropland (% of land area)\n",
      "AG.LND.EL5M.RU.K2: Rural land area where elevation is below 5 meters (sq. km)\n",
      "AG.LND.EL5M.RU.ZS: Rural land area where elevation is below 5 meters (% of total land area)\n",
      "AG.LND.EL5M.UR.K2: Urban land area where elevation is below 5 meters (sq. km)\n",
      "AG.LND.EL5M.UR.ZS: Urban land area where elevation is below 5 meters (% of total land area)\n",
      "AG.LND.EL5M.ZS: Land area where elevation is below 5 meters (% of total land area)\n",
      "AG.LND.FRST.K2: Forest area (sq. km)\n",
      "AG.LND.FRST.ZS: Forest area (% of land area)\n",
      "AG.LND.IRIG.AG.ZS: Agricultural irrigated land (% of total agricultural land)\n",
      "AG.LND.PRCP.MM: Average precipitation in depth (mm per year)\n",
      "AG.LND.TOTL.K2: Land area (sq. km)\n",
      "AG.LND.TOTL.RU.K2: Rural land area (sq. km)\n",
      "AG.LND.TOTL.UR.K2: Urban land area (sq. km)\n",
      "AG.PRD.CREL.MT: Cereal production (metric tons)\n",
      "AG.PRD.CROP.XD: Crop production index (2014-2016 = 100)\n",
      "AG.PRD.FOOD.XD: Food production index (2014-2016 = 100)\n",
      "AG.PRD.LVSK.XD: Livestock production index (2014-2016 = 100)\n",
      "AG.SRF.TOTL.K2: Surface area (sq. km)\n",
      "AG.YLD.CREL.KG: Cereal yield (kg per hectare)\n",
      "BG.GSR.NFSV.GD.ZS: Trade in services (% of GDP)\n",
      "BM.GSR.CMCP.ZS: Communications, computer, etc. (% of service imports, BoP)\n",
      "BM.GSR.FCTY.CD: Primary income payments (BoP, current US$)\n",
      "BM.GSR.GNFS.CD: Imports of goods and services (BoP, current US$)\n",
      "BM.GSR.INSF.ZS: Insurance and financial services (% of service imports, BoP)\n",
      "BM.GSR.MRCH.CD: Goods imports (BoP, current US$)\n",
      "BM.GSR.NFSV.CD: Service imports (BoP, current US$)\n",
      "BM.GSR.ROYL.CD: Charges for the use of intellectual property, payments (BoP, current US$)\n",
      "BM.GSR.TOTL.CD: Imports of goods, services and primary income (BoP, current US$)\n",
      "BM.GSR.TRAN.ZS: Transport services (% of service imports, BoP)\n",
      "BM.GSR.TRVL.ZS: Travel services (% of service imports, BoP)\n",
      "BM.KLT.DINV.CD.WD: Foreign direct investment, net outflows (BoP, current US$)\n",
      "BM.KLT.DINV.WD.GD.ZS: Foreign direct investment, net outflows (% of GDP)\n",
      "BM.TRF.PRVT.CD: Secondary income, other sectors, payments (BoP, current US$)\n",
      "BM.TRF.PWKR.CD.DT: Personal remittances, paid (current US$)\n",
      "BN.CAB.XOKA.CD: Current account balance (BoP, current US$)\n",
      "BN.CAB.XOKA.GD.ZS: Current account balance (% of GDP)\n",
      "BN.FIN.TOTL.CD: Net financial account (BoP, current US$)\n",
      "BN.GSR.FCTY.CD: Net primary income (BoP, current US$)\n",
      "BN.GSR.GNFS.CD: Net trade in goods and services (BoP, current US$)\n",
      "BN.GSR.MRCH.CD: Net trade in goods (BoP, current US$)\n",
      "BN.KAC.EOMS.CD: Net errors and omissions (BoP, current US$)\n",
      "BN.KLT.DINV.CD: Foreign direct investment, net (BoP, current US$)\n",
      "BN.KLT.PTXL.CD: Portfolio Investment, net (BoP, current US$)\n",
      "BN.RES.INCL.CD: Reserves and related items (BoP, current US$)\n",
      "BN.TRF.CURR.CD: Net secondary income (BoP, current US$)\n",
      "BN.TRF.KOGT.CD: Net capital account (BoP, current US$)\n",
      "BX.GRT.EXTA.CD.WD: Grants, excluding technical cooperation (BoP, current US$)\n",
      "BX.GRT.TECH.CD.WD: Technical cooperation grants (BoP, current US$)\n",
      "BX.GSR.CCIS.CD: ICT service exports (BoP, current US$)\n",
      "BX.GSR.CCIS.ZS: ICT service exports (% of service exports, BoP)\n",
      "BX.GSR.CMCP.ZS: Communications, computer, etc. (% of service exports, BoP)\n",
      "BX.GSR.FCTY.CD: Primary income receipts (BoP, current US$)\n",
      "BX.GSR.GNFS.CD: Exports of goods and services (BoP, current US$)\n",
      "BX.GSR.INSF.ZS: Insurance and financial services (% of service exports, BoP)\n",
      "BX.GSR.MRCH.CD: Goods exports (BoP, current US$)\n",
      "BX.GSR.NFSV.CD: Service exports (BoP, current US$)\n",
      "BX.GSR.ROYL.CD: Charges for the use of intellectual property, receipts (BoP, current US$)\n",
      "BX.GSR.TOTL.CD: Exports of goods, services and primary income (BoP, current US$)\n",
      "BX.GSR.TRAN.ZS: Transport services (% of service exports, BoP)\n",
      "BX.GSR.TRVL.ZS: Travel services (% of service exports, BoP)\n",
      "BX.KLT.DINV.CD.WD: Foreign direct investment, net inflows (BoP, current US$)\n",
      "BX.KLT.DINV.WD.GD.ZS: Foreign direct investment, net inflows (% of GDP)\n",
      "BX.PEF.TOTL.CD.WD: Portfolio equity, net inflows (BoP, current US$)\n",
      "BX.TRF.CURR.CD: Secondary income receipts (BoP, current US$)\n",
      "BX.TRF.PWKR.CD: Personal transfers, receipts (BoP, current US$)\n",
      "BX.TRF.PWKR.CD.DT: Personal remittances, received (current US$)\n",
      "BX.TRF.PWKR.DT.GD.ZS: Personal remittances, received (% of GDP)\n",
      "CC.EST: Control of Corruption: Estimate\n",
      "CC.NO.SRC: Control of Corruption: Number of Sources\n",
      "CC.PER.RNK: Control of Corruption: Percentile Rank\n",
      "CC.PER.RNK.LOWER: Control of Corruption: Percentile Rank, Lower Bound of 90% Confidence Interval\n",
      "CC.PER.RNK.UPPER: Control of Corruption: Percentile Rank, Upper Bound of 90% Confidence Interval\n",
      "CC.STD.ERR: Control of Corruption: Standard Error\n",
      "CM.MKT.INDX.ZG: S&P Global Equity Indices (annual % change)\n",
      "CM.MKT.LCAP.CD: Market capitalization of listed domestic companies (current US$)\n",
      "CM.MKT.LCAP.GD.ZS: Market capitalization of listed domestic companies (% of GDP)\n",
      "CM.MKT.LDOM.NO: Listed domestic companies, total\n",
      "CM.MKT.TRAD.CD: Stocks traded, total value (current US$)\n",
      "CM.MKT.TRAD.GD.ZS: Stocks traded, total value (% of GDP)\n",
      "CM.MKT.TRNR: Stocks traded, turnover ratio of domestic shares (%)\n",
      "DC.DAC.AUSL.CD: Net bilateral aid flows from DAC donors, Australia (current US$)\n",
      "DC.DAC.AUTL.CD: Net bilateral aid flows from DAC donors, Austria (current US$)\n",
      "DC.DAC.BELL.CD: Net bilateral aid flows from DAC donors, Belgium (current US$)\n",
      "DC.DAC.CANL.CD: Net bilateral aid flows from DAC donors, Canada (current US$)\n",
      "DC.DAC.CECL.CD: Net bilateral aid flows from DAC donors, European Union institutions (current US$)\n",
      "DC.DAC.CHEL.CD: Net bilateral aid flows from DAC donors, Switzerland (current US$)\n",
      "DC.DAC.CZEL.CD: Net bilateral aid flows from DAC donors, Czechia (current US$)\n",
      "DC.DAC.DEUL.CD: Net bilateral aid flows from DAC donors, Germany (current US$)\n",
      "DC.DAC.DNKL.CD: Net bilateral aid flows from DAC donors, Denmark (current US$)\n",
      "DC.DAC.ESPL.CD: Net bilateral aid flows from DAC donors, Spain (current US$)\n",
      "DC.DAC.ESTL.CD: Net bilateral aid flows from DAC donors, Estonia (current US$)\n",
      "DC.DAC.FINL.CD: Net bilateral aid flows from DAC donors, Finland (current US$)\n",
      "DC.DAC.FRAL.CD: Net bilateral aid flows from DAC donors, France (current US$)\n",
      "\n",
      "Your task:\n",
      "- Select indicators that are **strongly related to GDP growth**, **economic development**, or **structural transition** (e.g. education, infrastructure, industrialization, trade, institutions).\n",
      "- Prefer indicators that are **leading indicators** or have **causal influence** on development, not just GDP itself.\n",
      "- Include **diverse dimensions**: macroeconomic, infrastructure, education, health, technology, labor, governance, etc.\n",
      "- Limit to 2 indicators**.\n",
      "- Output only a Python dictionary like this:\n",
      "```python\n",
      "dict_indicators = {\n",
      "    'CODE1': 'Indicator Name 1',\n",
      "    'CODE2': 'Indicator Name 2',\n",
      "    ...\n",
      "} \n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-BOYiQDYFYE9ggZCb8azpijJ4sTjA6', choices=[CompletionChoice(finish_reason='stop', index=0, logprobs=None, text='')], created=1745193018, model='gpt-3.5-turbo-instruct:20230824-v2', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=None, prompt_tokens=2267, total_tokens=2267, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 2: Chunk the indicator list\n",
    "indicator_pairs = [f\"{i['id']}: {i['name']}\" for i in available_indicators]\n",
    "n_chunks = math.ceil(len(indicator_pairs) / CHUNK_SIZE)\n",
    "\n",
    "chunks = [\n",
    "    indicator_pairs[i * CHUNK_SIZE : (i + 1) * CHUNK_SIZE]\n",
    "    for i in range(n_chunks)\n",
    "]\n",
    "\n",
    "# Step 3: Run queries on each chunk and collect results\n",
    "merged_dict = {}\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"Running chunk {idx+1}/{n_chunks}...\")\n",
    "    chunk_text = \"\\n\".join(chunk)\n",
    "    prompt = base_prompt.replace(\"{chunked_indicators}\", chunk_text)\n",
    "    \n",
    "    try:\n",
    "        response = query_openai(prompt)\n",
    "\n",
    "        # Safely extract dictionary from response\n",
    "        chunk_dict = literal_eval(response.split(\"=\", 1)[-1].strip())\n",
    "        merged_dict.update(chunk_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing chunk {idx+1}: {e}\")\n",
    "\n",
    "# Final result\n",
    "print(\"✅ Merged dict_indicators created with\", len(merged_dict), \"indicators.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_indicators = query_openai(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "america_countries = [\n",
    "    'ARG', 'BLZ', 'BOL', 'BRA', 'CAN', 'CHL', 'COL', \n",
    "    'CRI', 'ECU', 'SLV', 'GTM', 'GUY', 'HND', 'MEX', \n",
    "    'NIC', 'PAN', 'PRY', 'PER', 'SUR', 'USA', 'URY', 'VEN'\n",
    "]\n",
    "\n",
    "df = wbdata.get_dataframe(dict_indicators, country=america_countries, parse_dates=True,date=(\"2000\", \"2025\"))\n",
    "df.reset_index(inplace = True)\n",
    "# df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate null rate by country\n",
    "null_rates = df.groupby('country').apply(lambda x: x.isnull().mean())\n",
    "\n",
    "# The country is already the index, so we don't need to reset it\n",
    "# Just transpose the DataFrame for better visualization\n",
    "null_rates = null_rates.T  # This puts countries as columns and variables as rows\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(\n",
    "    null_rates,\n",
    "    cmap='YlOrRd',\n",
    "    annot=True,\n",
    "    fmt='.1%',\n",
    "    linewidths=.5,\n",
    "    cbar_kws={'label': 'Null Rate'}\n",
    ")\n",
    "\n",
    "plt.title('Null Rate by Country and Column')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Variable')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is possible to see that the international migrant stock (% of popolation) isnt a god indicator, since most of its values are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate null rate by country\n",
    "null_rates = df.groupby('date').apply(lambda x: x.isnull().mean())\n",
    "\n",
    "# The country is already the index, so we don't need to reset it\n",
    "# Just transpose the DataFrame for better visualization\n",
    "null_rates = null_rates.T  # This puts countries as columns and variables as rows\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(\n",
    "    null_rates,\n",
    "    cmap='YlOrRd',\n",
    "    annot=True,\n",
    "    fmt='.1%',\n",
    "    linewidths=.5,\n",
    "    cbar_kws={'label': 'Null Rate'}\n",
    ")\n",
    "\n",
    "plt.title('Null Rate by Date')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Variable')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this heat maps, we can see that the international migran stock indicator is not a good  indicator for us, since in many years we dont have any values in it, so we need to change that, furthermore we can remove that 2024 year from our data ser, for the same reason. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4  # % of missingness\n",
    "\n",
    "null_rates_date_country = df.groupby(['country']).apply(lambda x: x.isnull().mean()).drop(columns = ['date','country'] )\n",
    "column_null_rates = null_rates_date_country.mean()\n",
    "columns_to_keep = column_null_rates[column_null_rates < threshold].index\n",
    "df_filtered = null_rates_date_country[columns_to_keep].reset_index()\n",
    "df_filtered = df_filtered[df.date < '2024-01-01'] # to remove 2024 from the data set\n",
    "\n",
    "print(f'Columns that have been dropped {list(column_null_rates[column_null_rates > threshold].index)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets replace that with new indicators, to furfill our goal to have at leat two indicators for each indicator group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
